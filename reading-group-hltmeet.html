<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <title>Lisbon Unit for Learning and Intelligent Systems - LUMLIS</title>
  <meta name="mobile-web-app-capable" content="yes">
  <meta name="keywords" content="LUMLIS, ELLIS, AI, Machine Learning, Instituto Superior Técnico, University of Lisbon, Lisbon, Portugal, Europe">
  <meta name="author" content="Bruno Martins">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#212121">
  <!-- include style sheet -->
  <link rel="stylesheet" media="all" href="ellis.css" />
  <!-- generic favicons -->
  <link rel="icon" href="images/lumlis-ellis-r-16.png" sizes="16x16" />
  <link rel="icon" href="images/lumlis-ellis-r-32.png" sizes="32x32" />
  <link rel="icon" href="images/lumlis-ellis-r-64.png" sizes="64x64" />
  <link rel="icon" href="images/lumlis-ellis-r-96.png" sizes="96x96" />
  <link rel="icon" href="images/lumlis-ellis-r-128.png" sizes="128x128" />
  <link rel="icon" href="images/lumlis-ellis-r-192.png" sizes="192x192" />
  <link rel="icon" href="images/lumlis-ellis-r-256.png" sizes="256x256" />
  <!-- Android (untested) -->
  <link rel="shortcut icon" sizes="196x196" href="images/lumlis-ellis-r-196.png">
  <!-- iOS -->
  <link rel="apple-touch-icon" href="images/lumlis-ellis-r-120.png" sizes="120x120">
  <link rel="apple-touch-icon" href="images/lumlis-ellis-r-152.png" sizes="152x152">
  <link rel="apple-touch-icon" href="images/lumlis-ellis-r-180.png" sizes="180x180">
  <!-- Windows (untested) -->
  <meta name="msapplication-TileColor" content="#212121"/>
  <meta name="msapplication-square70x70logo" content="images/lumlis-ellis-r-128.png"/>
  <meta name="msapplication-square150x150logo" content="images/lumlis-ellis-r-256.png"/>
  <meta name="msapplication-TileImage" content="images/lumlis-ellis-r-256.png"/>
  <meta name="msapplication-config" content="none"/>
  <!-- include javascript -->
  <script type="text/javascript" src="ellis.js"></script>
  <script type="text/javascript" src="tweetie.min.js"></script>
  <style type="text/css"></style>
</head>
<body class="scroll">
  <header class="fixed" style="clear:both;">
     <div class="colrow">
       <div class="seg m500-indigo"></div>
       <div class="seg m500-teal"></div>
       <div class="seg m500-orange"></div>
       <div class="seg m500-pink"></div>
       <div class="seg m500-dpurple"></div>
     </div>
     <div class="head">
       <a href="index.html" style="">LUMLIS - The Lisbon ELLIS Unit</a>
       <span class="dim" style="margin:0 0.25em;">|</span>
       <a href="people.html" style="">People</a>
       <span class="dim" style="margin:0 0.25em;">|</span>
       <a href="index.html#structure" style="">Structure</a>
       <span class="dim" style="margin:0 0.25em;">|</span>
       <a href="index.html#twitter" style="">News</a>	     
       <span class="dim" style="margin:0 0.25em;">|</span>
       <a href="index.html#events" style="">Events</a>	     
       <span class="dim" style="margin:0 0.25em;">|</span>
       <a href="companies.html" style="">Corporate Supporters</a>	
       <span class="dim" style="margin:0 0.25em;">|</span>
       <a href="index.html#contact" style="">Contact</a>     
     </div>
  </header>
  <main>
    <svg version="1.0" xmlns="http://www.w3.org/2000/svg"
     viewBox="0 0 843.000000 321.000000" style="width:20em; height:auto; float:right;" preserveAspectRatio="xMidYMid meet">
    <!-- composed to resemble OCRA -->
    <g transform="translate(0.000000,321.000000) scale(0.100000,-0.100000)" fill="currentColor" stroke="none">
    <!-- the "e" -->
    <path d="M910 2084 c-30 -8 -71 -25 -91 -38 -68 -45 -274 -237 -289 -269 -20
    -43 -28 -762 -10 -847 26 -116 66 -172 228 -312 81 -71 113 -93 145 -99 23 -5
    233 -8 467 -9 468 0 468 0 514 63 29 39 29 115 0 154 -46 62 -49 63 -480 63
    l-390 0 -60 36 c-115 69 -154 124 -154 218 l0 56 498 0 c548 0 539 -1 586 63
    20 26 21 44 24 249 2 130 -1 241 -8 270 -19 93 -58 155 -156 247 -122 115
    -179 148 -275 161 -119 15 -484 11 -549 -6z m535 -278 c46 -19 132 -101 156
    -148 16 -30 19 -59 19 -158 l0 -120 -415 0 -415 0 0 128 c1 81 5 135 13 148
    18 30 140 142 168 153 13 5 118 10 232 10 159 1 216 -2 242 -13z"
    class="m500-indigo ellis-e" style="fill:rgb(63,81,181)"/>
    <!-- first "l" -->
    <path d="M2310 2673 c-53 -27 -83 -78 -77 -132 6 -52 32 -90 78 -113 28 -15
    61 -18 187 -18 l152 0 0 -810 0 -810 -152 0 c-126 0 -159 -3 -187 -18 -52 -26
    -76 -65 -76 -122 0 -57 24 -96 76 -122 31 -16 75 -18 479 -18 490 0 488 0 534
    63 29 39 29 115 0 154 -40 54 -73 63 -241 63 l-153 0 0 893 c0 829 -1 894 -18
    926 -9 19 -30 44 -45 55 -27 20 -44 21 -275 24 -220 2 -251 1 -282 -15z"
    class="m500-teal ellis-l0" style="fill:rgb(0,150,136)"/>
    <!-- second "l" -->
    <path d="M3760 2673 c-53 -27 -83 -78 -77 -132 6 -52 32 -90 78 -113 28 -15
    61 -18 187 -18 l152 0 0 -810 0 -810 -152 0 c-169 0 -202 -9 -242 -63 -29 -39
    -29 -115 0 -154 46 -63 44 -63 534 -63 490 0 488 0 534 63 29 39 29 115 0 154
    -40 54 -73 63 -241 63 l-153 0 0 893 c0 829 -1 894 -18 926 -9 19 -30 44 -45
    55 -27 20 -44 21 -275 24 -220 2 -251 1 -282 -15z"
    class="m500-orange ellis-l1" style="fill:rgb(255,152,0)"/>
    <!-- "i" without the dot -->
    <path d="M5211 2083 c-75 -39 -102 -129 -59 -193 41 -61 73 -70 246 -70 l152
    0 0 -515 0 -515 -152 0 c-126 0 -159 -3 -187 -18 -52 -26 -76 -65 -76 -122 0
    -57 24 -96 76 -122 31 -16 75 -18 479 -18 404 0 448 2 479 18 52 26 76 65 76
    122 0 57 -24 96 -76 122 -28 15 -61 18 -186 18 l-153 0 0 598 c0 659 2 639
    -63 686 -27 20 -44 21 -275 24 -220 2 -251 1 -281 -15z"
    class="m500-pink ellis-i" style="fill:rgb(233,30,99)"/>
    <!-- small "a" on top of the "i" -->
    <path d="M5547 2813 c-11 -11 -8 -48 5 -61 7 -7 45 -12 99 -12 94 0 99 -3 99
    -58 l0 -27 -109 3 c-109 4 -109 4 -142 -26 -33 -29 -34 -33 -34 -107 0 -74 1
    -78 33 -106 30 -27 38 -29 115 -29 63 0 89 4 114 19 31 19 31 19 36 0 7 -25
    43 -25 57 0 5 11 10 84 10 166 0 223 -17 245 -183 245 -51 0 -97 -3 -100 -7z
    m184 -243 c31 -17 24 -55 -15 -79 -25 -16 -50 -21 -99 -21 -69 0 -77 6 -77 55
    0 51 7 55 92 55 44 0 88 -5 99 -10z"
    class="m500-pink ellis-a" style="fill:rgb(233,30,99)"/>
    <!-- the "s" -->
    <path d="M6835 2090 c-94 -23 -196 -105 -244 -195 -23 -44 -26 -61 -26 -145 1
    -85 4 -102 31 -160 60 -127 50 -120 634 -378 313 -139 357 -161 377 -191 42
    -62 23 -168 -37 -208 -32 -23 -38 -23 -346 -23 l-313 0 -53 25 c-29 14 -75 40
    -102 58 -39 25 -60 32 -98 32 -44 0 -53 -4 -83 -37 -36 -39 -51 -91 -40 -135
    17 -71 173 -176 306 -208 87 -20 678 -22 754 -1 183 49 325 222 325 396 0 180
    -88 332 -232 402 -31 15 -228 102 -439 193 -211 91 -390 173 -396 182 -21 27
    -15 72 12 98 l24 25 326 0 c361 0 343 3 430 -69 83 -68 141 -67 212 3 54 55
    57 91 12 159 -58 89 -154 154 -257 176 -60 12 -727 14 -777 1z"
    class="m500-dpurple ellis-s" style="fill:rgb(103,58,183)"/>
    </g>
    </svg>
    <div class="nobreak" style="text-align:left;"><h1>Lisbon Unit for Learning and Intelligent Systems</h1></div>
	
    <div class="spacer" style="height:2em;"></div>
	
    <div class="nobreak" style="text-align:left;">
    We are pleased to announce the creation of the Lisbon Unit for Learning and Intelligent Systems (LUMLIS), a unit of the
    <a href="https://ellis.eu/">European Laboratory for Learning and Intelligent Systems</a> (ELLIS), hosted at the <a href="https://tecnico.ulisboa.pt/">Instituto Superior Técnico</a> (IST) of the <a href="https://www.ulisboa.pt">University of Lisbon</a> (UL).</div>
    
    <div class="spacer" style="height:2em;"></div>
	
    <section id="overview">
    <div class="nobreak"><h2>The HLTmeet Reading Group @ INESC-ID</h2>
    This reading group meets regularly to discuss research topics on different sub-fields of Speech and Natural Language Processing.</div>
    </section>

    <div class="spacer" style="height:2em;"></div>
    
    <div class="nobreak" style="text-align:center;"><img width="85%" alt="INESC-ID" src="photos/inescid.jpg" href="https://www.inesc-id.pt"></div>
	  
    <div class="spacer" style="height:2em;"></div>

    <section id="structure">
    <div class="nobreak"><h2>Reading Group Schedule</h2>
	
<table style="width:100%;border: 2px solid #bbb; text-align:left;">
    <tr>
    <td style="text-align:left;background: #36546F;font-size:17px;color:#FDF5E6;" colspan="3">
	Winter Term 2022-2023
	    <span style="float:right;padding-right:15px">
		    Wednesdays at 4:00 PM (room 336 or <a href="https://videoconf-colibri.zoom.us/j/97372580444" style="color: yellow"> Zoom </a>)
	    </span>
    </td>
    </tr>
    <tr>
    <td style="white-space: nowrap;text-align:left;background: #36546F;font-size:17px;color:#FDF5E6;">Date </td>
    <td style="white-space: nowrap;text-align:left;background: #36546F;font-size:17px;color:#FDF5E6;">Presenter</td>
    <td style="white-space: nowrap;text-align:left;background: #36546F;font-size:17px;color:#FDF5E6;">Topic</td>
    </tr>
    <tr style="background-color:#E6E9EC">
        <td style="white-space: nowrap;"> Oct 12 </td>
        <td> Carlos Carvalho </td>
        <td> Robust Self-Supervised Audio-Visual Speech Recognition - <a href="https://arxiv.org/pdf/2201.01763.pdf"> [paper] </a></td>
    </tr>
    <tr>
        <td style="border-width: thick; border-color: #36546F;"> Oct 19 </td>
        <td> </td>
        <td> Discussion about ICASSP and Interspeech papers </td>
    </tr>
	<tr style="background-color:#E6E9EC">
        <td style="white-space: nowrap;"> Oct 26 </td>
        <td> Gonçalo Raposo </td>
        <td> Memorizing Transformers - <a href="https://openreview.net/pdf?id=TrjbxzRcnf-"> [paper] </a></td>
    </tr> 
    <tr>
        <td style="border-width: thick; border-color: #36546F;"> Nov 2 </td>
        <td> Francisco Teixeira </td>
        <td> Introducing Model Inversion Attacks on Automatic Speaker Recognition - <a href="https://www.isca-speech.org/archive/pdfs/spsc_2022/pizzi22_spsc.pdf"> [paper] </a></td>
    </tr>
	<tr style="background-color:#E6E9EC">
        <td style="white-space: nowrap;"> Nov 9 </td>
        <td> Thomas Rolland </td>
        <td> AudioLM: a Language Modeling Approach to Audio Generation - <a href="https://arxiv.org/pdf/2209.03143.pdf"> [paper] </a></td>
    </tr> 
    <tr>
        <td style="border-width: thick; border-color: #36546F;"> Nov 23 </td>
        <td> Higo Pires </td>
        <td> Evaluation of Sentiment Analysis in Finance: From Lexicons to Transformers - <a href="https://repository.ukim.mk/bitstream/20.500.12188/8903/1/09142175.pdf"> [paper] </a></td>
    </tr>
	<tr style="background-color:#E6E9EC">
        <td style="white-space: nowrap;"> Nov 30 </td>
        <td> Rubén Solera-Ureña </td>
        <td> The Importance of Speech Stimuli for Pathologic Speech Classification - <a href="https://arxiv.org/pdf/2210.15941.pdf"> [paper] </a></td>
    </tr> 
    <tr>
        <td style="border-width: thick; border-color: #36546F;"> Jan 4 </td>
        <td> Catarina Botelho </td>
        <td> ChatGPT - <a href="https://openai.com/blog/chatgpt/"> [blog post] </a></td>
    </tr>
	<tr style="background-color:#E6E9EC">
        <td style="white-space: nowrap;"> Jan 11 </td>
        <td> John Mendonça </td>
        <td> The Forward-Forward Algorithm: Some Preliminary Investigations - <a href="https://www.cs.toronto.edu/~hinton/FFA13.pdf"> [paper] </a></td>
    </tr> 
    <tr>
        <td style="border-width: thick; border-color: #36546F;"> Jan 18 </td>
        <td> Mariana Julião </td>
        <td> On the Utility of Self-supervised Models for Prosody-related Tasks - <a href="https://arxiv.org/pdf/2210.07185.pdf"> [paper] </a></td>
    </tr>
	<tr style="background-color:#E6E9EC">
        <td style="white-space: nowrap;"> Jan 25 </td>
        <td> Alberto Abad </td>
        <td> FLEURS: Few-shot Learning Evaluation of Universal Representations of Speech - <a href="https://arxiv.org/pdf/2205.12446.pdf"> [paper] </a></td>
    </tr> 
    <tr>
        <td style="border-width: thick; border-color: #36546F;"> Feb 1 </td>
        <td> Patrícia Pereira </td>
        <td> Does GPT-3 Generate Empathetic Dialogues? A Novel In-Context Example Selection Method and Automatic Evaluation Metric for Empathetic Dialogue Generation - <a href="https://aclanthology.org/2022.coling-1.56.pdf"> [paper] </a></td>
    </tr>
	<tr style="background-color:#E6E9EC">
        <td style="white-space: nowrap;"> Feb 8 </td>
        <td> Isabel Trancoso </td>
        <td> On the Predictive Power of Objective Intelligibility Metrics for the Subjective Performance of Deep Complex Convolutional Recurrent Speech Enhancement Networks - <a href="https://www.techrxiv.org/articles/preprint/On_the_Predictive_Power_of_Objective_Intelligibility_Metrics_for_the_Subjective_Performance_of_Deep_Complex_Convolutional_Recurrent_Speech_Enhancement_Networks/19698502/1"> [paper] </a></td>
    </tr> 
</table>

<br/>
<br/>
	
<table style="width:100%;border: 2px solid #bbb; text-align:left;">
    <tr>
    <td style="text-align:left;background: #36546F;font-size:17px;color:#FDF5E6;" colspan="3">
	Summer Term 2022-2023
	    <span style="float:right;padding-right:15px">
		    Wednesdays at 4:00 PM (room 336 or <a href="https://videoconf-colibri.zoom.us/j/97372580444" style="color: yellow"> Zoom </a>)
	    </span>
    </td>
    </tr>
    <tr>
    <td style="white-space: nowrap;text-align:left;background: #36546F;font-size:17px;color:#FDF5E6;">Date </td>
    <td style="white-space: nowrap;text-align:left;background: #36546F;font-size:17px;color:#FDF5E6;">Presenter</td>
    <td style="white-space: nowrap;text-align:left;background: #36546F;font-size:17px;color:#FDF5E6;">Topic</td>
    </tr>	
    <tr>
        <td style="white-space: nowrap; border-width: thick; border-color: #36546F;"> Feb 22 </td>
        <td> Carlos Carvalho </td>
        <td> Regeneration Learning: A Learning Paradigm for Data Generation - <a href="https://arxiv.org/pdf/2301.08846.pdf"> [paper] </a></td>
    </tr>
	<tr style="background-color:#E6E9EC">
        <td style="white-space: nowrap;"> Mar 1 </td>
        <td> Gonçalo Raposo </td>
        <td> GPTScore: Evaluate as You Desire - <a href="https://arxiv.org/pdf/2302.04166.pdf"> [paper] </a></td>
    </tr>
    <tr>
        <td style="border-width: thick; border-color: #36546F;"> Mar 15 </td>
        <td> Fernando Batista </td>
        <td> Expanding Pretrained Models to Thousands More Languages via Lexicon-based Adaptation - <a href="https://aclanthology.org/2022.acl-long.61.pdf"> [paper] </a></td>
    </tr>
	<tr style="background-color:#E6E9EC">
        <td style="white-space: nowrap;"> Mar 22 </td>
        <td> Thomas Rolland </td>
        <td> Synt++: Utilizing Imperfect Synthetic Data to Improve Speech Recognition - <a href="https://arxiv.org/pdf/2110.11479.pdf"> [paper] </a> <br>
             Towards Data Selection on TTS Data for Children’s Speech Recognition - <a href="https://ieeexplore.ieee.org/document/9413930"> [paper] </a> </td>
    </tr> 
    <tr>
        <td style="border-width: thick; border-color: #36546F;"> Mar 29 </td>
        <td> Francisco Teixeira </td>
        <td> Encoder-Decoder Based Attractors for End-to-End Neural Diarization - <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9741374"> [paper] </a></td>
    </tr>
	<tr style="background-color:#E6E9EC">
        <td style="white-space: nowrap;"> April 5 </td>
        <td> Higo Pires </td>
        <td> Benchmarking Zero-shot Text Classification: Datasets, Evaluation and Entailment Approach - <a href="https://aclanthology.org/D19-1404.pdf"> [paper] </a></td>
    </tr> 
    <tr>
        <td style="border-width: thick; border-color: #36546F;"> April 12 </td>
        <td> Catarina Botelho </td>
        <td> Machine Love - <a href="https://arxiv.org/pdf/2302.09248.pdf"> [paper] </a></td>
    </tr>
	<tr style="background-color:#E6E9EC">
        <td style="white-space: nowrap;"> April 19 </td>
        <td> Rubén Solera-Ureña </td>
        <td> Tips and tricks for researchers and reviewers </td>
    </tr> 
    <tr>
        <td style="border-width: thick; border-color: #36546F;"> April 26 </td>
        <td> John Mendonça </td>
        <td> Sparks of Artificial General Intelligence: Early experiments with GPT-4 - <a href="https://arxiv.org/pdf/2303.12712.pdf"> [paper] </a></td>
    </tr>
	<tr style="background-color:#E6E9EC">
        <td style="white-space: nowrap;"> May 3 </td>
        <td> Mariana Julião </td>
        <td> Truth Is a Lie: Crowd Truth and the Seven Myths of Human Annotation - <a href="https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/2564/2468"> [paper] </a></td>
    </tr> 
    <tr>
        <td style="border-width: thick; border-color: #36546F;"> May 10 </td>
        <td> Patrícia Pereira </td>
        <td> Is ChatGPT Equipped with Emotional Dialogue Capabilities? - <a href="https://arxiv.org/pdf/2304.09582.pdf"> [paper] </a></td>
    </tr> 
	<tr style="background-color:#E6E9EC">
        <td style="white-space: nowrap;"> May 24 </td>
        <td> Francisco Teixeira and<br/> Anna Havras </td>
        <td> ICASSP work and Master's thesis - <a href=""> [paper] </a></td>
    </tr> 
    <tr>
        <td style="border-width: thick; border-color: #36546F;"> May 31 </td>
    	<td> Isabel Trancoso </td>
        <td> Interpreting Deep Representations of Phonetic Features via Neuro-Based Concept Detector: Application to Speech Disorders Due to Head and Neck Cancer - <a href="https://ieeexplore.ieee.org/document/9944907"> [paper] </a></td>
    </tr>
	<tr style="background-color:#E6E9EC">
        <td style="white-space: nowrap;"> Jun 21 </td>
        <td> Carlos Carvalho </td>
        <td> Structured Pruning of Self-Supervised Pre-trained Models for Speech Recognition and Understanding - <a href="https://arxiv.org/pdf/2302.14132.pdf"> [paper] </a></td>
    </tr> 
    <tr>
	<td style="border-width: thick; border-color: #36546F;"> Jun 28 </td>
        <td> Rubén Solera-Ureña </td>
        <td> Federated Learning for ASR based on Wav2vec 2.0 - <a href="https://arxiv.org/pdf/2302.10790.pdf"> [paper] </a></td>
    </tr>
	<tr style="background-color:#E6E9EC">
        <td style="white-space: nowrap;"> Jul 5 </td>
        <td> Gonçalo Raposo </td>
        <td> DialGuide: Aligning Dialogue Model Behavior with Developer Guidelines - <a href="https://arxiv.org/pdf/2212.10557.pdf"> [paper] </a></td>
    </tr> 
    <tr>
        <td style="border-width: thick; border-color: #36546F;"> Jul 19 </td>
        <td> Alberto Abad </td>
        <td> Sumformer: A Linear-Complexity Alternative to Self-Attention for Speech Recognition - <a href="https://arxiv.org/pdf/2307.07421.pdf"> [paper] </a></td>
    </tr>
	<tr style="background-color:#E6E9EC">
        <td style="white-space: nowrap;"> Jul 26 </td>
        <td> Thomas Rolland </td>
        <td> Reducing Barriers to Self-Supervised Learning: HuBERT Pre-training with Academic Compute - <a href="https://arxiv.org/pdf/2306.06672.pdf"> [paper] </a></td>
    </tr>
	<tr>
        <td style="border-width: thick; border-color: #36546F;"> Sep 13 </td>
        <td> Catarina Botelho <br>
		Mariana Julião </td>
        <td> Careful Whisper - leveraging advances in automatic speech recognition for robust and interpretable aphasia subtype classification - <a href="https://www.isca-speech.org/archive/pdfs/interspeech_2023/zusag23_interspeech.pdf"> [paper] </a> <br>
		The Androids Corpus: A New Publicly Available Benchmark for Speech Based Depression Detection - <a href="https://www.isca-speech.org/archive/pdfs/interspeech_2023/tao23_interspeech.pdf"> [paper] </a> <br>
		Towards robust paralinguistic assessment for real-world mobile health (mHealth) monitoring: an initial study of reverberation effects on speech - <a href="https://www.isca-speech.org/archive/pdfs/interspeech_2023/dineley23_interspeech.pdf"> [paper] </a> <br>
		Which aspects of motor speech disorder are captured by Mel Frequency Cepstral Coefficients? Evidence from the change in STN-DBS conditions in Parkinson’s disease - <a href="https://www.isca-speech.org/archive/pdfs/interspeech_2023/illner23_interspeech.pdf"> [paper] </a> <br>
		Why We Should Report the Details in Subjective Evaluation of TTS More Rigorously - <a href="https://www.isca-speech.org/archive/interspeech_2023/chiang23_interspeech.html"> [paper] </a> <br>
		Speech Self-Supervised Representation Benchmarking: Are We Doing it Right? - <a href="https://www.isca-speech.org/archive/interspeech_2023/zaiem23b_interspeech.html"> [paper] </a></td>
	</tr>
	<tr style="background-color:#E6E9EC">
        <td style="white-space: nowrap;"> Sep 20 </td>
        <td> Francisco Teixeira </td>
        <td> Malafide: a novel adversarial convolutive noise attack against deepfake and spoofing detection systems - <a href="https://www.isca-speech.org/archive/pdfs/interspeech_2023/panariello23b_interspeech.pdf"> [paper] </a> <br>
		Vocoder drift in x-vector–based speaker anonymization - <a href="https://www.isca-speech.org/archive/pdfs/interspeech_2023/panariello23_interspeech.pdf"> [paper] </a> <br>
		Mutual Information-based Embedding Decoupling for Generalizable Speaker Verification - <a href="https://www.isca-speech.org/archive/pdfs/interspeech_2023/li23r_interspeech.pdf"> [paper] </a> <br>
		pyannote.audio 2.1 speaker diarization pipeline: principle, benchmark, and recipe - <a href="https://www.isca-speech.org/archive/pdfs/interspeech_2023/bredin23_interspeech.pdf"> [paper] </a></td>
	</tr>
    <tr>
        <td style="border-width: thick; border-color: #36546F;"> Sep 27 </td>
        <td> Carlos Carvalho <br>
		Francisco Teixeira </td>
        <td> AfriNames: Most ASR Models "Butcher" African Names - <a href="https://www.isca-speech.org/archive/pdfs/interspeech_2023/olatunji23_interspeech.pdf"> [paper] </a> <br>
		MT4SSL: Boosting Self-Supervised Speech Representation Learning by Integrating Multiple Targets - <a href="https://www.isca-speech.org/archive/pdfs/interspeech_2023/ma23d_interspeech.pdf"> [paper] </a> <br>
		Reproducing Whisper-Style Training Using an Open-Source Toolkit and Publicly Available Data - <a href="https://arxiv.org/pdf/2309.13876.pdf"> [paper] </a></td>
    </tr>
	<tr style="background-color:#E6E9EC">
        <td style="white-space: nowrap;"> Oct 4 </td>
        <td> John Mendonça <br>
		Gonçalo Raposo </td>
        <td> The Timing Bottleneck: Why Timing and Overlap Are Mission-Critical for Conversational User Interfaces, Speech Recognition and Dialogue Systems - <a href="https://sigdialinlg2023.github.io/static/papers/sigdial/19_Paper.pdf"> [paper] </a> <br>
			ChatGPT vs. Crowdsourcing vs. Experts: Annotating Open-Domain Conversations With Speech Functions - <a href="https://sigdialinlg2023.github.io/static/papers/sigdial/156_Paper.pdf"> [paper] </a> <br>
			Leveraging Large Language Models for Automated Dialogue Analysis - <a href="https://sigdialinlg2023.github.io/static/papers/sigdial/106_Paper.pdf"> [paper] </a> <br>
			The Open-Domain Paradox for Chatbots: Common Ground as the Basis for Human-Like Dialogue - <a href="https://sigdialinlg2023.github.io/static/papers/sigdial/81_Paper.pdf"> [paper] </a> <br>
			Approximating Online Human Evaluation of Social Chatbots With Prompting - <a href="https://sigdialinlg2023.github.io/static/papers/sigdial/15_Paper.pdf"> [paper] </a> <br>
			Memories for Virtual AI Characters - <a href="https://sigdialinlg2023.github.io/static/papers/inlg/99_Paper.pdf"> [paper] </a></td>
    </tr>
    <tr>
        <td style="border-width: thick; border-color: #36546F;"> Oct 18 </td>
        <td> Carlos Carvalho </td>
        <td> Transformers learn through gradual rank increase - <a href="https://arxiv.org/pdf/2306.07042.pdf"> [paper] </a></td>
    </tr>
<!-- <tr style="background-color:#E6E9EC">
        <td style="white-space: nowrap;"> Month day </td>
        <td> To be announced </td>
        <td> To be announced - <a href=""> [paper] </a></td>
    </tr> 
    <tr>
        <td style="border-width: thick; border-color: #36546F;"> Month day </td>
        <td> To be announced </td>
        <td> To be announced - <a href=""> [paper] </a></td>
    </tr> -->
</table>	    
	    
    </div>
    </section>

    <div class="spacer" style="height:5em;"></div>

  </main>
  <footer>
    <div>LUMLIS - The Lisbon ELLIS Unit <span class="dim">|</span> <a href="https://ellis.eu/">European Laboratory for Learning and Intelligent Systems</a>.</div>
    <div id="contact" style="opacity:0.75; margin-top:0.75em;">
       Contact:<br>
       <li style="display:inline-block; margin-left:2em;"><b>Enquiries</b> – Mário A. T. Figueiredo (mario.figueiredo<span>@</span>tecnico.ulisboa.pt)</li>
       <li style="display:inline-block; margin-left:2em;"><b>Web &amp; Content</b> – André F. T. Martins (andre.t.martins<span>@</span>tecnico.ulisboa.pt)</li>
    </div>
  </footer>
  <div class="colrow">
    <div class="seg m500-indigo"></div>
    <div class="seg m500-teal"></div>
    <div class="seg m500-orange"></div>
    <div class="seg m500-pink"></div>
    <div class="seg m500-dpurple"></div>
  </div>
</body>
</html>
